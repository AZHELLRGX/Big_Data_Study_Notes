### 初识Kafka

特性：高吞吐、可持久化、可水平扩展、支持流数据处理

Kafka目前在业界主要扮演3个主要角色：

#### 消息系统

Kafka 和传统的消息系统（也称作消息中间件）都具备系统解耦、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等功能。与此同时，Kafka 还提供了大多数消息系统难以实现的***消息顺序性保障及回溯消费的功能***。

#### 存储系统

Kafka 把消息持久化到磁盘，相比于其他基于内存存储的系统而言，有效地降低了数据丢失的风险。也正是得益于Kafka 的消息***持久化功能和多副本机制***，我们可以把Kafka作为长期的数据存储系统来使用

#### 流式处理平台

Kafka 不仅为每个流行的流式处理框架提供了可靠的数据来源，还提供了一个完整的流式处理类库，比如窗口、连接、变换和聚合等各类操作。非常适合与Flink等流式计算框架结合构建大数据实时数仓。

### 基本概念

一个典型的 Kafka 体系架构包括若干 Producer、若干 Broker、若干 Consumer，以及一个ZooKeeper集群

#### 职责划分

其中ZooKeeper是Kafka用来负责集群元数据的管理、控制器的选举等操作的。

Producer将消息发送到Broker，Broker负责将收到的消息存储到磁盘中，而Consumer负责从Broker订阅并消费消息。

![img](%E7%AC%94%E8%AE%B0.assets/epub_25462424_3)

整个Kafka体系结构中引入了以下3个术语。

- Producer：生产者，也就是发送消息的一方。生产者负责创建消息，然后将其投递到Kafka中。
- Consumer：消费者，也就是接收消息的一方。消费者连接到Kafka上并接收消息，进而进行相应的业务逻辑处理。
- Broker：服务代理节点。对于Kafka而言，Broker可以简单地看作一个独立的Kafka服务节点或Kafka服务实例。***大多数情况下也可以将Broker看作一台Kafka服务器，前提是这台服务器上只部署了一个Kafka实例***。一个或多个Broker组成了一个Kafka集群。一般而言，我们更习惯使用首字母小写的broker来表示服务代理节点。

#### 主题与分区

在Kafka中还有两个特别重要的概念—主题（Topic）与分区（Partition）

- 一个主题可以包含多个分区，而一个分区只属于一个主题
- 分区可以在存储层面视为一个可追加的日志文件，消息追加到日志文件的时候会分配一个特定的偏移量offset，它是消息在分区中的唯一标识，分区也是通过它进行排序的，但是offset不跨越分区，所以***Kafka的消息是分区有序而不是主题有序***
- Kafka中的分区可以分布在不同的服务器（broker）上，也就是说，一个主题可以横跨多个broker，以此来提供比单个broker更强大的性能。

![img](%E7%AC%94%E8%AE%B0.assets/epub_25462424_4)

#### 多副本机制

Kafka 为分区引入了多副本（Replica）机制，通过增加副本数量可以提升容灾能力。同一分区的不同副本中保存的是相同的消息（在同一时刻，副本之间并非完全一样），副本之间是“一主多从”的关系，其中leader副本负责处理读写请求，follower副本只负责与leader副本的消息同步。副本处于不同的broker中，当leader副本出现故障时，从follower副本中重新选举新的leader副本对外提供服务。Kafka通过多副本机制实现了故障的自动转移，当Kafka集群中某个broker失效时仍然能保证服务可用。【这个设计有点类似与ES的设计，果然优秀的高可用设计都是类似的】

![img](%E7%AC%94%E8%AE%B0.assets/epub_25462424_5)

如上图所示，Kafka集群中有4个broker，某个主题中有3个分区，且副本因子（即副本个数）也为3，如此每个分区便有1个leader副本和2个follower副本。生产者和消费者只与leader副本进行交互，而follower副本只负责消息的同步，很多时候follower副本中的消息相对leader副本而言会有一定的滞后。

#### AR、ISR、OSR

- 分区中的所有副本统称为AR（Assigned Replicas），所有与leader副本保持一定程度同步（这是一个可忍受的值，可以通过参数配置）的副本（包括leader副本在内）组成ISR（In-Sync Replicas）；与leader副本同步滞后过多的副本（不包括leader副本）组成OSR（Out-of-Sync Replicas），由此可见，AR=ISR+OSR；在正常情况下，所有的 follower 副本都应该与 leader 副本保持一定程度的同步，即 AR=ISR，OSR集合为空
- leader副本负责维护和跟踪ISR集合中所有follower副本的滞后状态，当follower副本落后太多或失效时，leader副本会把它从ISR集合中剔除。如果OSR集合中有follower副本“追上”了leader副本，那么leader副本会把它从OSR集合转移至ISR集合；默认情况下，当leader副本发生故障时，只有在ISR集合中的副本才有资格被选举为新的leader（当然这是默认规则，可以通过参数配置）
- Kafka使用的这种ISR的方式则有效地权衡了数据可靠性和性能之间的关系。

#### 消费端的容灾能力

Kafka 消费端也具备一定的容灾能力。Consumer 使用拉（Pull）模式从服务端拉取消息，并且保存消费的具体位置，当消费者宕机后恢复上线时可以根据之前保存的消费位置重新拉取需要的消息进行消费，这样就不会造成消息丢失。

### 生产与消费

####  创建topic

```shell
kafka-topics.sh --zookeeper localhost:2181 --create --topic topic-demo --replication-factor 0 --partitions 4
kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topic-demo --replication-factor 0 --partitions 4
```

#### 展示主题信息

```shell
kafka-topics.sh --zookeeper localhost:2181 --describe --topic topic-demo
```

#### 消费消息

```shell
kafka-console-consumer.sh --bootstrap-server 192.168.2.101:9092 --topic topic-demo
```

#### 生产消息

```shell
kafka-console-producer.sh --broker-list 192.168.2.101:9092 --topic topic-demo
```

### 服务端参数配置

#### zookeeper.connect

### 生产者

#### maven配置

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>org.azhell</groupId>
    <artifactId>kakfa-java-dev</artifactId>
    <version>1.0.0</version>

    <properties>
        <maven.compiler.source>8</maven.compiler.source>
        <maven.compiler.target>8</maven.compiler.target>
    </properties>

    <dependencies>
        <!-- https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients -->
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka-clients</artifactId>
            <version>2.8.0</version>
        </dependency>
    </dependencies>
</project>
```

#### 客户端Java代码

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;

import java.util.Properties;

public class KafkaProducerAnalysis {
    private static final String BROKER_LIST = "192.168.2.101:9092";
    private static final String TOPIC = "topic-demo";

    private static Properties initConfig() {
        Properties properties = new Properties();
        properties.put("bootstrap.servers",BROKER_LIST);
        // 设置消息的序列化组件
        properties.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("client.id", "producer.client.id.demo");
        return properties;
    }

    public static void main(String[] args) {
        Properties properties = initConfig();
        try (KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties)) {
            ProducerRecord<String, String> producerRecord = new ProducerRecord<>(TOPIC, "hello, kafka");
            kafkaProducer.send(producerRecord);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

> 在生产者客户端有三个数据是必填的：
>
> - `bootstrap.servers`：该参数用来指定生产者客户端连接Kafka集群所需的broker地址清单，具体的内容格式为`host1：port1，host2：port2`，可以设置一个或多个地址，中间以逗号隔开，此参数的默认值为“”；建议设置至少两个地址，防止因为broker死亡而无法生产消息
> - `key.serializer` 和 `value.serializer：broker` 端接收的消息必须以字节数组（byte[]）的形式存在；分别用来指定key和value序列化操作的序列化器，这两个参数无默认值。注意这里必须填写序列化器的全限定名
> - `initConfig()`方法里还设置了一个参数`client.id`，这个参数用来设定`KafkaProducer`对应的客户端id，默认值为“”。如果客户端不设置，则`KafkaProducer`会自动生成一个非空字符串，内容形式如“producer-1”、“producer-2”，即字符串“producer-”与数字的拼接。

#### `ProducerRecord`属性说明

```java
public class ProducerRecord<K, V> {
    private final String topic; // 主题
    private final Integer partition; // 分区号
    private final Headers headers; // 消息头部
    private final K key; // 键
    private final V value; // 值
    private final Long timestamp; // 消息的时间戳
    
	public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value, Iterable<Header> headers) {
        if (topic == null)
            throw new IllegalArgumentException("Topic cannot be null.");
        if (timestamp != null && timestamp < 0)
            throw new IllegalArgumentException(
                    String.format("Invalid timestamp: %d. Timestamp should always be non-negative or null.", timestamp));
        if (partition != null && partition < 0)
            throw new IllegalArgumentException(
                    String.format("Invalid partition: %d. Partition number should always be non-negative or null.", partition));
        this.topic = topic;
        this.partition = partition;
        this.key = key;
        this.value = value;
        this.timestamp = timestamp;
        this.headers = new RecordHeaders(headers);
    }
    
    // .....其他构造器都是简化了一个参数的输入
```

> - 它大多用来设定一些与应用相关的信息，如无需要也可以不用设置
> - key是用来指定消息的键，它不仅是消息的附加信息，还可以用来计算分区号进而可以让消息发往特定的分区。前面提及消息以主题为单位进行归类，而这个key可以让消息再进行二次归类，同一个key的消息会被划分到同一个分区中；有key的消息还可以支持日志压缩的功能
> - value是指消息体，一般不为空，如果为空则表示特定的消息—墓碑消息
> - `timestamp`是指消息的时间戳，它有`CreateTime`和`LogAppendTime`两种类型，前者表示消息创建的时间，后者表示消息追加到日志文件的时间
> - `ProducerRecord`还有很多其他的构造方法，可以自行查阅相关接口文档

#### `ProducerConfig`

上文中的参数设置不易记忆，而且容易写错，可以通过`ProducerConfig`来规避错误

```java
properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
```

#### `KafkaProducer`[线程安全]

> - `KafkaProducer`是线程安全的，可以在多个线程中共享单个`KafkaProducer`实例，也可以将`KafkaProducer`实例进行池化来供其他线程调用。
> - `KafkaProducer `中有多个构造方法，比如在创建` KafkaProducer` 实例时并没有设定`key.serializer` 和`value.serializer` 这两个配置参数，那么就需要在构造方法中添加对应的序列化器；但是不推荐这种写法
>
> > ```java
> > KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties,new StringSerializer(),new StringSerializer())
> > ```

#### 消息发送模式

发送消息主要有三种模式：发后即忘（fire-and-forget）、同步（sync）及异步（async）

发送消息的send方法的返回值并不是void类型，而是两个同名的重载方法：

```java
public Future<RecordMetadata> send(ProducerRecord<K, V> record) {
        return send(record, null);
    }
public Future<RecordMetadata> send(ProducerRecord<K, V> record, Callback callback) {
        // intercept the record, which can be potentially modified; this method does not throw exceptions
        ProducerRecord<K, V> interceptedRecord = this.interceptors.onSend(record);
        return doSend(interceptedRecord, callback);
    }
```

上面的示例其实就是发后即忘模式，只管发送，不关心发送是否成功，这种模式性能很好，但是可靠性很差

##### 同步

而同步模式就是通过调用Future类型返回值的get()方法来达到阻塞的目的，这样可以保证数据发送成功，不成功可能会有两种异常：

- 可重试的异常；常见的可重试异常有：`NetworkException`、`LeaderNotAvailableException`、`UnknownTopicOrPartitionException`、`NotEnoughReplicasException`

> 比如`NetworkException` 表示网络异常，这个有可能是由于网络瞬时故障而导致的异常，可以通过重试解决；又比如`LeaderNotAvailableException`表示分区的leader副本不可用，这个异常通常发生在leader副本下线而新的 leader 副本选举完成之前，重试之后可以重新恢复

- 不可重试的异常；比如`RecordTooLargeException`异常

> `RecordTooLargeException`异常暗示了所发送的消息太大，`KafkaProducer`对此不会进行任何重试，直接抛出异常

对于可重试的异常，可以通过配置重试次数来保证失败重试：

```java
properties.put(ProducerConfig.RETRIES_CONFIG, 10);
```

如果超过重试次数仍未成功，则也会类似不可重试异常一样直接抛出，外层业务逻辑仍然需要处理这些异常。

##### 异步

再来了解一下异步发送的方式，一般是在send（）方法里指定一个Callback的回调函数，Kafka在返回响应时调用该函数来实现异步的发送确认。其实send方法的Future返回值也可以实现异步调用，只不过Future里的 get() 方法在何时调用，以及怎么调用都是需要面对的问题，消息不停地发送，那么诸多消息对应的Future对象的处理难免会引起代码处理逻辑的混乱。使用Callback的方式非常简洁明了，Kafka有响应时就会回调，要么发送成功，要么抛出异常。

```java
kafkaProducer.send(producerRecord, new Callback() {
    @Override
    public void onCompletion(RecordMetadata metadata, Exception exception) {
        if (exception != null){
            exception.printStackTrace();
        }else{
            System.out.println(metadata.partition() + "-" + metadata.offset());;
        }
    }
});
```

> - `onCompletion()`方法的两个参数是互斥的，消息发送成功时，`metadata` 不为 null 而`exception`为null；消息发送异常时，`metadata`为null而`exception`不为null
> - 对于同一个分区而言，如果消息record1于record2之前先发送（参考上面的示例代码），那么KafkaProducer就可以保证对应的callback1在callback2之前调用，也就是说，***回调函数的调用也可以保证分区有序***。

#### 序列化

- 生产者需要用序列化器（Serializer）把对象转换成字节数组才能通过网络发送给Kafka。而在对侧，消费者需要用反序列化器（Deserializer）把从 Kafka 中收到的字节数组转换成相应的对象

- 除了用于String类型的序列化器，还有ByteArray、ByteBuffer、Bytes、Double、Integer、Long这几种类型，它们都实现了org.apache.kafka.common.serialization.Serializer接口，此接口有3个方法：

```java
default void configure(Map<String, ?> configs, boolean isKey) {
        // intentionally left blank
}

byte[] serialize(String topic, T data);

default byte[] serialize(String topic, Headers headers, T data) {
    return serialize(topic, data);
}

@Override
default void close() {
    // intentionally left blank
}
```

> configure（）方法用来配置当前类，serialize（）方法用来执行序列化操作。而close（）方法用来关闭当前的序列化器，一般情况下 close（）是一个空方法，如果实现了此方法，则必须确保此方法的幂等性，因为这个方法很可能会被KafkaProducer调用多次。

#### 分区器

息在通过send（）方法发往broker的过程中，有可能需要经过拦截器（Interceptor）、序列化器（Serializer）和分区器（Partitioner）的一系列作用之后才能被真正地发往 broker。拦截器一般不是必需的，而序列化器是必需的。消息经过序列化以后，会有两种决定发往哪个分区的方式：

- 如果消息`ProducerRecord`中指定了partition字段，那么就不需要分区器的作用，因为partition代表的就是所要发往的分区号。
- 如果消息`ProducerRecord`中没有指定partition字段，那么就需要依赖分区器，根据key这个字段来计算partition的值。分区器的作用就是为消息分配分区。
- Kafka中提供的默认分区器是`org.apache.kafka.clients.producer.internals.DefaultPartitioner`，它实现了`org.apache.kafka.clients.producer.Partitioner`接口，这个接口中定义了2个方法：

```java
// 用来计算分区号，返回int类型，参数分别表示主题、键、序列化后的键、值、序列化后的值，以及集群的元数据信息
public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);

public void close();
```

在默认分区器 `DefaultPartitioner` 的实现中，close（）是空方法，而在 partition（）方法中定义了主要的分区分配逻辑：

```java
public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
        return partition(topic, key, keyBytes, value, valueBytes, cluster, cluster.partitionsForTopic(topic).size()); // 从集群元信息中获取集群的分区总数
}

public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster,int numPartitions) {
    if (keyBytes == null) {
        // 如果key为null，那么消息将会以轮询的方式发往主题内的各个可用分区
        return stickyPartitionCache.partition(topic, cluster);
    }
    // 采用MurmurHash2算法，具备高运算性能及低碰撞率
    return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
}
```

> ***注意***：
>
> - 如果 key 不为 null，那么计算得到的分区号会是所有分区中的任意一个；如果 key为null，那么计算得到的分区号仅为可用分区中的任意一个，注意两者之间的差别。
>
> - 在不改变主题分区数量的情况下，key与分区之间的映射可以保持不变。不过，一旦主题中增加了分区，那么就难以保证key与分区之间的映射关系了。

#### 生产者拦截器

生产者拦截器既可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。

生产者拦截器的使用也很方便，主要是自定义实现`org.apache.kafka.clients.producer.ProducerInterceptor`接口。`ProducerInterceptor`接口中包含3个方法：

```java
// KafkaProducer在将消息序列化和计算分区之前会调用生产者拦截器的onSend（）方法来对消息进行相应的定制化操作
public ProducerRecord<K, V> onSend(ProducerRecord<K, V> record);
// KafkaProducer 会在消息被应答（Acknowledgement）之前或消息发送失败时调用生产者拦截器的onAcknowledgement（）方法，优先于用户设定的 Callback 之前执行;这个方法运行在Producer的 I/O 线程中，所以这个方法中实现的代码逻辑越简单越好，否则会影响消息的发送速度。
public void onAcknowledgement(RecordMetadata metadata, Exception exception);
public void close();
```

> - 多个拦截器使用逗号分割，拦截顺序是依次从前往后
>
> ```java
> properties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, AddPrefixInterceptor.class.getName()+"," +  AddPrefixInterceptor.class.getName());
> ```
>
> - 拦截器链中，如果有一个拦截器拦截出现异常，下一个拦截器则会从前一个拦截成功的拦截器的处理结果继续工作

### 生产者客户端原理分析

![img](%E7%AC%94%E8%AE%B0.assets/epub_25462424_80)

#### 线程模型

整个生产者客户端由两个线程协调运行，这两个线程分别为主线程和Sender线程（发送线程）。在主线程中由`KafkaProducer`创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器（`RecordAccumulator`，也称为消息收集器）中。Sender 线程负责从`RecordAccumulator`中获取消息并将其发送到Kafka中。

#### `RecordAccumulator `

- RecordAccumulator 主要用来缓存消息以便 Sender 线程可以批量发送，进而减少网络传输的资源消耗以提升性能。RecordAccumulator 缓存的大小可以通过生产者客户端参数buffer.memory 配置，默认值为 33554432B，即 32MB。如果生产者发送消息的速度超过发送到服务器的速度，则会导致生产者空间不足，这个时候KafkaProducer的send（）方法调用要么被阻塞，要么抛出异常，这个取决于参数max.block.ms的配置，此参数的默认值为60000，即60秒，超过这个时间还在阻塞就会抛出异常

- 主线程中发送过来的消息都会被追加到RecordAccumulator的某个双端队列（Deque）中，在RecordAccumulator 的内部为*每个分区*都维护了一个双端队列，队列中的内容就是ProducerBatch，即 Deque＜ProducerBatch＞。消息写入缓存时，追加到双端队列的尾部；Sender读取消息时，从双端队列的头部读取。

#### `ProducerBatch`

注意ProducerBatch不是ProducerRecord，ProducerBatch中可以包含一至多个 ProducerRecord。通俗地说，ProducerRecord 是生产者中创建的消息，而ProducerBatch是指一个***消息批次***，ProducerRecord会被包含在ProducerBatch中，这样可以使字节的使用更加紧凑。与此同时，将较小的ProducerRecord拼凑成一个较大的ProducerBatch，也可以减少网络请求的次数以提升整体的吞吐量。ProducerBatch和消息的具体格式有关。如果生产者客户端需要向很多分区发送消息，则可以将buffer.memory参数适当调大以增加整体的吞吐量。

> question：这里的buffer.memory设置是对单个ProducerBatch生效还是对整个RecordAccumulator 生效呢？留作后续回来解答

#### `BufferPool`

- 消息在网络上都是以字节（Byte）的形式传输的，在发送之前需要创建一块内存区域来保存对应的消息。在Kafka生产者客户端中，通过java.io.ByteBuffer实现消息内存的创建和释放。不过频繁的创建和释放是比较耗费资源的，在RecordAccumulator的内部还有一个BufferPool，它主要用来实现ByteBuffer的复用，以实现缓存的高效利用。不过BufferPool只针对特定大小的ByteBuffer进行管理，而其他大小的ByteBuffer不会缓存进BufferPool中，这个特定的大小由batch.size参数来指定，默认值为16384B，即16KB。我们可以适当地调大batch.size参数以便多缓存一些消息。

- ProducerBatch的大小和batch.size参数也有着密切的关系。当一条消息（ProducerRecord）流入RecordAccumulator时，会先寻找与消息分区所对应的双端队列（如果没有则新建），再从这个双端队列的尾部获取一个 ProducerBatch（如果没有则新建），查看 ProducerBatch 中是否还可以写入这个 ProducerRecord，如果可以则写入，如果不可以则需要创建一个新的ProducerBatch。在新建ProducerBatch时评估这条消息的大小是否超过batch.size参数的大小，如果不超过，那么就以batch.size 参数的大小来创建 ProducerBatch，这样在使用完这段内存区域之后，可以通过BufferPool 的管理来进行复用；如果超过，那么就以评估的大小来创建ProducerBatch，这段内存区域不会被复用。

#### 消息发送过程中的逻辑转换

- Sender 从 RecordAccumulator 中获取缓存的消息之后，会进一步将原本＜分区，Deque＜ProducerBatch＞＞的保存形式转变成＜Node，List＜ ProducerBatch＞的形式，其中Node表示Kafka集群的broker节点。对于网络连接来说，生产者客户端是与具体的broker节点建立的连接，也就是向具体的 broker 节点发送消息，而并不关心消息属于哪一个分区；而对于 KafkaProducer的应用逻辑而言，我们只关注向哪个分区中发送哪些消息，所以在这里需要做一个应用逻辑层面到网络I/O层面的转换。

- 在转换成＜Node，List＜ProducerBatch＞＞的形式之后，Sender 还会进一步封装成＜Node，Request＞的形式，这样就可以将Request请求发往各个Node了，这里的Request是指Kafka的各种协议请求，对于消息发送而言就是指具体的 ProduceRequest。

#### `InFlightRequests`

请求在从Sender线程发往Kafka之前还会保存到InFlightRequests中，InFlightRequests保存对象的具体形式为 Map＜NodeId，Deque＜Request＞＞，它的主要作用是缓存了已经发出去但还没有收到响应的请求（NodeId 是一个 String 类型，表示节点的 id 编号）。与此同时，InFlightRequests还提供了许多管理类的方法，并且通过配置参数还可以限制每个连接（也就是客户端与Node之间的连接）最多缓存的请求数。这个配置参数为max.in.flight.requests.per.connection，默认值为 5，即每个连接最多只能缓存 5 个未响应的请求，超过该数值之后就不能再向这个连接发送更多的请求了，除非有缓存的请求收到了响应（Response）。通过比较Deque＜Request＞的size与这个参数的大小来判断对应的Node中是否已经堆积了很多未响应的消息，如果真是如此，那么说明这个 Node节点负载较大或网络连接有问题，再继续向其发送请求会增大请求超时的可能。

### 消费者

#### 消费者与消费组

- 换言之，每一个分区只能被一个消费组中的一个消费者所消费

### 主题与分区

#### 主题的管理

主题的管理包括创建主题、查看主题信息、修改主题和删除主题等操作

##### kafka-topics.sh脚本

这个脚本其实只有一行:

```shell
exec $(dirname $0)/kafka-run-class.sh kafka.admin.TopicCommand "$@"
```

其实质上是调用了kafka.admin.TopicCommand类来执行主题管理的操作

##### KafkaAdminClient

这种方式实质上是通过发送 CreateTopicsRequest、DeleteTopicsRequest 等请求来实现的

##### 创建主题

- 参数auto.create.topics.enable决定生产者和消费者操作一个不存在的主题时，是否创建该主题。这个参数的默认值是true，它会创建一个分区数为num.partitions （默认值为1）、副本因子为default.replication.factor（默认值为1）的主题；不建议将该值设置为true，这会导致主题管理的混乱
- 更加推荐使用kafka-topics.sh脚本来创建主题：

```shell
# 创建一个分区数是4，副本因子是2的名为topic-create的主题
kafka-topics.sh --zookeeper 192.168.2.101:2181 --create --topic topic-create --replication-factor 2 --partitions 4
```

脚本执行后，kafka会在log.dir或者log.dirs参数所配置的路径创建相应的主题分区，这个参数可以在server.properties中找到

```properties
log.dirs=/data/kafka/kafka-logs
```

当前集群有三个节点：

> 192.168.2.101:
> drwxr-xr-x 2 hmaster root  161 6月  15 20:15 topic-create-0
> drwxr-xr-x 2 hmaster root  161 6月  15 20:15 topic-create-2
> drwxr-xr-x 2 hmaster root  161 6月  15 20:15 topic-create-3
>
> 192.168.2.102:
> drwxr-xr-x 2 hmaster root  161 6月  15 20:15 topic-create-0
> drwxr-xr-x 2 hmaster root  161 6月  15 20:15 topic-create-1
>
> 192.168.2.103:
> drwxr-xr-x 2 hmaster root  161 6月  15 20:15 topic-create-1
> drwxr-xr-x 2 hmaster root  161 6月  15 20:15 topic-create-2
> drwxr-xr-x 2 hmaster root  161 6月  15 20:15 topic-create-3
>
> >- 一共创建了8个目录，因为分区数 * 副本因子刚好是8
> >
> >- 同一个分区的多个副本必须分配到不用的broker，这样才可以尽可能提供数据冗余，支持数据容灾
> >- ![img](%E7%AC%94%E8%AE%B0.assets/epub_25462424_208)





